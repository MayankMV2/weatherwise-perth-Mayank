
This project took me from raw weather data to a small, working “Weather Advisor” for Perth that fetches a seven-day forecast, visualises it, and answers everyday questions. I began by testing fetch_my_weather/wttr.in, but the default three-day horizon limited the charts and Q&A. To meet the brief (clear visuals and conversational answers over a week), I switched to the Open-Meteo daily API (no key required) with forecast_days=7. I converted the response into a tidy DataFrame with stable columns—date, tmin_c, tmax_c, precip_mm, precip_prob, wind_max_kmh, uv_max—so plotting and question-answering stayed decoupled from the API’s raw JSON.
For visualisation, I implemented two views: a line chart for min/max temperature and a precipitation view. Perth’s week can be completely dry, so I added a simple fallback: if all precip_mm values are zero, show precip_prob (%) as a line instead of empty bars. This kept the chart informative without inventing data. On the conversational side, I wrote a lightweight parser that recognises “today”, “tomorrow”, weekday names, and ISO dates, and returns friendly answers about umbrellas, wind, UV, and hottest/wettest days. A small timezone tweak anchors “today/tomorrow” to Australia/Perth to avoid off-by-one issues when Colab runs in UTC. I also included a tiny menu for all over the project.
I used AI intentionally and logged the interactions in plain .txt files. Helpful sessions included: choosing Open-Meteo to get seven days without a key; mapping API fields into a consistent DataFrame; designing the precipitation/ probability fallback; refining the Q&A rules (umbrella when precip_prob ≥ 50% or precip_mm ≥ 1.0); and the timezone fix. I learned that concise, constraint-driven prompts (“map these fields to these exact columns”) produce better results than broad requests. I also compared alternative approaches (staying with wttr.in vs. switching; future-only data vs. including past days) and documented why I picked the final path.
The main challenges were scope (3 vs. 7 days), empty precipitation charts, and robust date interpretation. Each was solved with small, testable changes: different API parameters, a visual fallback, and a timezone-aware parser. Technically, this reinforced API handling, data wrangling with pandas, simple but meaningful plotting, and rule-based natural-language logic. Process-wise, it showed how to use AI as a partner: to explore options, spot edge cases, and iterate quickly while still making final design decisions myself.
If I extend this, I’d add hourly views, simple alerts (e.g., high UV or strong winds), cached requests to reduce network calls, unit tests for the Q&A parser, and a lightweight UI so users can switch locations. Overall, the result meets the brief and demonstrates a clear, iterative development process supported by AI.
